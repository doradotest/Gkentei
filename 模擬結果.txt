223問中127問正解 56% 6/6
１〇重み
２〇バイアス
３〇活性化関数

４〇訓練誤差
５〇最小化
６〇汎化誤差

７〇確率的勾配降下法
８〇逐次学習
９〇ミニバッチ学習
１０〇バッチ学習

１１〇隠れ層のユニット数が増えるほど,複雑な関数を近似する能力が上がる

１２〇順伝播型ニューラルネットワーク
１３ｘ　正解：3全結合層　あなたの回答：4　畳み込み層
１４〇プーリング層

１５ｘ　正解：2　ファインチューニング
１６〇入力層に近い中間層

１７〇再帰構造
１８〇系列データ
１９〇情報を一時的に記憶させること

２０ｘ正解：2　自己符号化器　あなたの回答：3RNN（Recurrent Neural Networks）
２１〇長い系列を遡るにつれて学習が困難になる

22〇SGD,RMSProp,Adam
23x 正解：5 SGD あなたの回答：1 Adam
24x 正解：3 ミニバッチ あなたの回答：4 バッチ

25〇 （ア）勾配消失
26〇（イ）重み更新
27x （ウ）正解：3 ReLU あなたの回答：2正則化
28x  （エ）正解：1
 あなたの回答：3ドロップアウト
29x （オ）正解：2 あなたの回答：3

21・29 75%
30〇CNN
31x 正解：4 LSTM なたの回答：6 RNN
32x 正解：6 RNN あなたの回答：1 GMM

33〇

34x 正解：1 CNN あなたの回答：3 DNN
35〇 畳み込み
36〇 プーリング

37x

38x

39〇 転移学習
40x 正解：1 出力層の再学習 あなたの回答：4 入力層の再学習
41〇 学習率

42x 正解：2 あなたの回答：1
43〇

44x

45〇

46x

47〇
48〇
49〇
50〇

33/50 66%

51〇
52〇
53x

54〇
55〇

56〇
57〇

58〇
59x
60〇
61〇

62x
63x
64x
65〇
66x

67〇
68-

69x
70〇

71〇
72x

73〇
74〇
75x

76-
77〇

78x
79〇
80〇
81〇
82x

83〇
84〇
85〇

86〇

87〇
88x

89〇
90〇
91〇
92〇

93x

94〇
95〇

96〇
97x
98x

99〇
100x

101x
102〇
103x
104〇
105〇

106x
107-
108-

109-
110〇

111x
112x
113-

114x

115-
116x
117〇

118-
119〇
120-
121-

122〇
123-
124x
125〇
126〇

127x
128x

129-
130〇
131〇

132〇
133〇

134〇
135〇
136〇

137〇
138〇
139x
140x

141x
142〇
143〇
144〇
145〇

146-
147-
148-

149〇
150〇
151〇

152〇
153〇
154〇

155x

156-
157x

158〇
159〇

160x
161x
162〇

163〇
164〇
165〇
166〇
167〇

168x
169x
170〇

171〇
172〇

173x
174〇
175〇
176-

177x

178〇
179〇
180x

181〇
182〇
183x

184〇
185〇

186〇
187x

188〇
189x

190〇
191-
192-
193-

194x

195〇
196x

197〇
198〇
199〇
200〇

201〇
202〇
203〇

204〇
205〇
206〇
207〇

208-
209-
210-


211-

212〇
213-

214-


215-


216x
217x


218x
219〇

220-

221-


222x


223-


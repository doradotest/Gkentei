+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
1 		データエンジニアの役割 	② 	5.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
◆データ分析に使われるツール
・Jupyter
・Notebook
・NumPy（データの入手や加工などのハンドリング）
・Pandas（データの入手や加工などのハンドリング）（データの可視化）
・Matplotlib（データの可視化）
・SciPy サイパイ
・scikit-learn（機械学習）

■データサイエンティスト
数学、情報工学、対象分野の専門知識（ドメイン知識）

役割
・モデルやアルゴリズム構築
・新たな解法や新技術への取り組み。★研究分野においては、
・解決したい課題に向き合う実務    ★実務においては
・データとの向き合い方の提示
・分析結果の評価

ドメイン知識とは、解析しようとしている業界や事業についての知識や知見、トレンドなどの情報です

■データ分析エンジニア
データ工学を実践する１つの職種

■データハンドリング（前処理）

■機械学習以外
・ルールベース
　　if文

・統計的手法
　　機械学習に親和性あり

■機械学習
学習方式
・教師あり学習　
　　【正解となる目的となるデータ（目的変数）があることが前提】
　　説明変数　目的変数を説明するためのデータ　（特徴量、特徴データともいいます）
　　回帰　目的変数が連続値
　　分類　目的変数がカテゴライズされているデータ　連続値以外
・教師なし学習
　　クラスタリング　与えられたデータの中からグル^ピング
　　次元削減　大量データを少なくする

■機械学習の処理手順
・データ入力
・データ加工
・データ可視化
・アルゴリズム選択
・学習プロセス ハイパーパラメーター
・精度評価
・試験運用
・結果利用

■パッケージ
pythonに機能を追加したり支援したりするためのもの
・外部のパッケージ
・サードパーティ製パッケージ

・Jupyter　notebook　拡張子　.ipynb
・NumPy

〇データサイエンティストの役割には、モデルやアルゴリズム構築、新たな解法や新技術への取り組み、解決したい課題に向き合う実務、分析結果の評価などがある。
〇データサイエンティストの役割は、研究分野と実務で多少の違いがある。研究分野においては、【新たな解法や新技術への取り組み】が重視され、実務においては、【解決したい課題に向き合う部分】が重視される。
〇データ分析に利用されるプログラミング言語には、Python、R、Julia、Excel、【Visual Basic for Applications】などがある。
〇Pythonでデータ分析に使われる主なパッケージには、Jupyter Notebook、NumPy、pandas、Matplotlib、SciPy、scikit-learnなどがある。
ＸPythonはデータ分析以外の分野でも活用されており、Webアプリなどのフロントエンド、【速度向上のための低レイヤー処理】などの分野においても他のプログラミング言語に比して優位性が高い。

Ｘ教師あり学習の１つであるDBSCAN法は密度準拠クラスタリングアルゴリズムであり、特徴量ベクトル間の距離に着眼した手法である。
〇★教師あり学習は、正解となるラベルデータが存在する場合に用いられる方式であり、【そのラベルを目的変数】という。
Ｘ★教師あり学習は、【説明変数】の種類により回帰と分類の２種類に分けられる。回帰は目的変数が連続値となる。
Ｘ★教師なし学習は、正解ラベルを用いない学習方法であり、クラスタリングや次元削減といったタスクを行う。典型的なものに【ニューラルネットワークを用いた深層学習】がある。
Ｘ★強化学習は、ブラックボックス的な環境の中で行動するエージェントが、得られる報酬を最大化するように学習する方法であり、ルールベースと比較される機械学習の【伝統的な手法】である。

＊DBSCAN法とは（教科書では特に言及はされていないのですが）「特徴量ベクトル間の距離に着眼した手法」つまりデータ間のそれぞれの特徴を基に学習する手法です。
ですから「教師あり学習」ではなく、「教師なし学習」とするのが正しい

〇Pythonでデータ分析に使われる主なパッケージには、Jupyter Notebook、NumPy、pandas、Matplotlib、Scipy、scikit-learnなどがある。

Ｘデータサイエンティストの役割は、研究分野と実務で多少の違いがある。研究分野においては解決したい課題に向き合う部分が重視され、実務においては新たな解法や新技術への取り組みが重視される。

〇データ分析エンジニアは、情報工学を基盤としてデータベース技術からデータの活用まで幅広くデータと向き合う学術分野、つまりデータ工学を実践する一つの職種として位置づけることができる。
〇データ分析に利用されるサードパーティ製パッケージの一つにSciPyがある。これは【科学技術計算】をサポートするものであり、scikit-learnの内部で高度な計算処理に多用されている。
ｘサードパーティ製パッケージであるpandasが提供するDataFrame構造は、C言語【R言語】のデータフレームからインスパイアされたものであり、表形式の2次元データを柔軟に取り扱えるという特徴がある。
〇データ分析を行う上でデータハンドリングは重要な役割を持つ。データハンドリングは前処理ともいわれ、データの入手や再加工、つなぎ合わせや可視化など、データ分析を行う上で何度も実行されるものである。

ｘ教師あり分類の場合の機械学習の処理手順は、データ入手の後に精度評価、そしてデータ加工・可視化、アルゴリズム選択、学習プロセスへと進むのが一般的である。
ｘ教師なし学習は、正解ラベルを用いない学習方法であり、クラスタリングや次元削減といったタスクを行う。典型的なものに強化学習がある。
〇機械学習を用いずにカテゴライズや数値予測を行う手法の一つとして、ルールベースがある。ルールベースではプログラミングの条件分岐の要領でデータを容易にルール化できるが、
　パラメータの数が増えると記述が困難になる。
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
2 		Pythonと環境	1 	実行環境構築 	① 	2.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


★Python -m venv venv-test

dir  venv-test

    ディレクトリ: C:\Users\worke\venv-test


Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----        2021/04/25      0:11                Include
d-----        2021/04/25      0:11                Lib
d-----        2021/04/25      0:11                Scripts
-a----        2021/04/25      0:11             80 pyvenv.cfg


PS C:\Users\worke> venv-test\Scripts\Activate.ps1　★★★
(venv-test) PS C:\Users\worke> deactivate　終了　★★★　
PS C:\Users\worke>

rm -r -fo venv-test　仮想環境のディレクトリ削除

pip サードパーティ製パッケージをインスト

PyPIサイト　

pip install numpy==1.14.1  バージョン指定　★★★　
pip install -U　numpy　最新版に更新　★★★　



PS D:\dev\py> pip list
WARNING: Ignoring invalid distribution -ip (d:\appt\python38\lib\site-packages)
Package    Version
---------- -------
pip        21.1
setuptools 49.2.1
wheel      0.36.2

cd D:\dev\py

python D:\dl\get-pip.py   再インストール

PS D:\dev\py> pip -V
pip 21.1 from d:\appt\python38\lib\site-packages\pip (python 3.8)

pip install -U pip ★★

PS D:\dev\py>  pip list -o　新しいバージョンの存在★★
Package    Version Latest Type
---------- ------- ------ -----
setuptools 49.2.1  56.0.0 wheel


#プロジェクトのバージョン統一
PS D:\dev\py\venv-test> pip freeze > requirements.txt★★

pip install -r requirements.txt★★

Anaconda
condaコマンド

＊venvはPythonの下に組み込まれる機能なので、Python自体のバージョン管理はできません。

〇pipコマンドは、【The Python Package Index】 に公開されているPythonパッケージのインストールなどを行うユーティリティであり、パッケージをインストールするにはpip installコマンドを使用する。
〇AnacondaはAnaconda社が開発、配布しているPythonのディストリビューションであり、venv、pipとは異なる仮想環境の作成方法、パッケージ管理システムを採用している。
〇Pythonでは、シンプルで読みやすいコードが書けることを設計思想として文法が作られている。コードのブロック構造をカッコではなくインデントで表現するところにもその思想が表れている。
Ｘ★venvはPythonの仮想環境を作成する仕組みである。WindowsでもmacOSでも利用することができ【異なるバージョンのPython言語を使い分けるのに便利】である。
〇★Pythonには【PEP 8】と呼ばれる標準となるコーディング規約が存在する。たとえば、複数のモジュールをインポートするときには、１行ずつインポートして書くべきとされている。

作成したプログラムがPEP8に違反していないかチェックするツールとして【Flake8】がある。

ｘvenvはPythonの仮想環境をWindowsやmacOS、Linuxで作成する仕組みである。仮想環境が有効になるとコマンドプロンプトに環境名が表示される。仮想環境を無効化する（抜ける）には、quitコマンドを実行する。
〇Anacondaで設定した環境下でパッケージ管理をする場合には、Anaconda独自のcondaコマンドのほかpipも利用可能である。ただし稀にcondaコマンドで構築された環境がpipの利用で壊されてしまうこともあるため、
　Anacondaを利用する場合は基本的にcondaコマンドでパッケージ管理することが望ましい。
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
2 		Pythonと環境	2 	Pythonの基礎 	③ 	7.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
コーディング規約　PEP8　（ペップエイト）

複数のモジュールをインポートするときは1行づつImportする

スタイルチェックツール　pycodestyle★

pycodestyle sample.py

論理総合チェック　Flake8

s1.strip 左右の空白削除

s1.title 一文字目を大文字　Talabe　Tetuji★
s1.endwith(('jpg','gif','png')) 末尾チェック
'123456'.isdigit() 数字文字列かチェック
'py' in s1   文字が含まれるか★

■内包表記
[len(name) for name in names]  # 文字列の長さのリスト★を作成
[4, 3, 4]
{len(name) for name in names}  # 文字列の長さのセット★を作成
{3, 4}
{name: len(name) for name in names}  # 文字列とその長さの辞書を生成
{'spam': 4, 'ham': 3, 'eggs': 4}
[x*x for x in range(10) if x % 2 == 0]
[[(y, x*x) for x in range(10) if x % 2 == 0] for y in range(3)]
[[(0, 0), (0, 4), (0, 16), (0, 36), (0, 64)],
 [(1, 0), (1, 4), (1, 16), (1, 36), (1, 64)],
 [(2, 0), (2, 4), (2, 16), (2, 36), (2, 64)]]

■ジェネレーター式
g = (x*x for x in range(10000))  # ジェネレーター式で定義

type(g) ---》 generator# 型を確認

next(g), next(g), next(g)  # 値を順番に取り出せる
(0, 1, 4)

次の正規表現を用いたスクリプトの[ ア ]の部分に入れたときエラーとなるものはどれか。

import re
prog = re.compile('Kus(a|u)n(a|o|k)g?i(saya|ro)?', re.IGNORECASE)
[ ア ]
print(ret[0])
　ret = prog.search('KUS　A　N　A　G　I')
　ret = prog.search('Kus　a　n　a　g　i saya')　＜--注意
◎ret = prog.search('Kus　u　n　o　　　ki')
　ret = prog.search('KUS　A　N　O　G　I')
　ret = prog.search('Kus　a　n　o　　　iro')

IGNORECASEフラグ（大文字小文字を区別しない）の設定
gには直後に疑問符がついているのでゼロ個または1個です。★★★

〇loggingモジュールはログレベルを指定して任意のファイルにフォーマットを指定してログの出力を行うことができ、たとえば、バッチ処理などの途中経過を出力する用途に用いる。
〇loggingモジュールのログレベルには、重要度の低い順にDEBUG、INFO、WARNING、ERROR、CRITICALの5つがある。
Ｘ★★pickleモジュールは、Pythonのオブジェクトをシリアライズしてファイルなどで読み書きできるようにすることができ、標準出力をバッファリングして制御するために便利である。
〇Pythonでファイルのパスを扱うにはpathlibモジュールが便利である。globメソッドではファイル名をワイルドカード(*)で指定することもできる。
〇日付などの処理にはdatetimeモジュールが便利である。たとえば、過去の日付から今日の日付を差し引いて経過日数を計算することができる。

〇pickleモジュールは、Pythonのオブジェクトを直列化してファイルなどで読み書きできるようにすることができる。pickle化できるものとして【ブール値や数値、文字列】などがある。
〇日付などの処理にはdatetimeモジュールが便利である。たとえば、【nowメソッド】では現在日時を取得することができる。

標準　（DEBUG INFO ）WARNING　ERROR　CRITICAL　
+++++++++++++++++++++++++++++++++ ++++++++++++++++++++++++++
2 		Pythonと環境	3 	Jupyter Notebook 	① 	2.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
もともとはIpython notebookというツール名で開発されていた。
pythonだけでなく、R言語、juliaも対応したもの

python3 -m venv pydataenv  -->[pydataenv]仮想環境構築
source pydataenv/bin/activate
pip install jupyter==1.0.0


(pydataenv) D:\doc\ipython\dev\pydataenv>pip install jupyter==1.0.0

マジックコマンド
　%timeit
  %%timeit

シェルコマンド
　！pip list

notebookファイルはjson形式で記述

〇Jupyter Notebookはオープンソースで開発されているデータ分析、可視化、機械学習などに広く利用されているWebアプリケーションである。
〇Notebookファイルは保存することができ、その拡張子は【.ipynb】である。
〇マジックコマンドは%または%%からはじまる特別なコマンドで、たとえば、プログラムの実行時間を複数回試行して計測を行うコマンドもある。
〇シェルコマンドはOSのコマンドを指定して実行することができる。たとえば、pip listコマンドを実行することもできる。
ＸNotebookファイルはYAML形式で記述されており、プログラムや結果を参照するためには基本的にはJupyter Notebookを実行する必要があるが、yumなどのリポジトリサービスはNotebookファイルの表示に対応しているため、これらを利用して参照することができる。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
3 		数学の基礎 		1 	数式を読むための基礎知識 	① 	2.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 集合Sに属する
　ｘ∈Ｓ
　∉　属さない

積集合　共通部分

	A∩B

和集合

	A∪B

空集合　∅

n個の数字のまとまり

x1,･･･,xn
xi(i=1,･･･,n))

・足し算の繰り返し★★
　　x1からxnまで全て足す　シグマ
　　∑k=1ak

・掛け算の繰り返し
　　∏　パイ★★

・階乗
    n! n～1まで掛け合わせる
　　6!=6x5x4x3x2x1
　　0!=1
・ネイピア数（自然対数の底）★★
　e=2.71828

・指数関数★★
　　f(x)=2x
　　シグモイド関数　ニューラルネットワークでよく使われる★★★★★★

・対数関数★★
　　f(8)=3 2を何乗すれば８になるか　２を底という★★
　　入力された値が」、底の何乗になるか
　　底がネイピア数のとき、自然対数と呼ぶ★★
　　底が10のとき、常用対数とよばれる★★
・三角関数
　　水平方向　COS　余弦
　　垂直方法　SIN　正弦

　　ラジアン　１周を２πとする★★★★★★

　　tan（タンジェント　正接）＝SIN/COS

双曲線関数

〇数式で、足し算の繰り返しを表す際にはギリシャ文字のシグマの大文字を用い、掛け算の繰り返しを表す際には、ギリシャ文字のパイの大文字を用いる。
〇★直径が1のときの円周の長さを円周率と呼び、自然対数の底をネイピア数と呼ぶ。【両者とも小数点以下を四捨五入すると3になる】。
〇★関数の入力が別の数字の肩に乗って使われる関数を指数関数と呼び、入力された値が底の何乗に相当するかという出力を行う関数を対数関数と呼ぶ。
〇★★★★★★指数関数を応用した関数にシグモイド関数がある。シグモイド関数は、深層学習の基本的な技術であるニューラルネットワークでよく使われる。
Ｘ三角関数のsinは「サイン」と読み、日本語では上弦という呼び名がある。また、cosは「コサイン」と読み、日本語では下弦という呼び名がある。

＊三角関数のサイン、コサイン、タンジェントはそれぞれ、正弦、余弦、正接です。
＊自然対数の底をネイピア数と呼ぶ

〇★★★シグモイド関数のグラフの形は、座標点（0, 0.5）を基点として点対象の、S字型曲線である。
〇数式で足し算の繰り返しを表す際には、ギリシャ文字のシグマの大文字を用い、プログラムではそのままは実行できない「無限大まで足し算を繰り返す」という動作も表現できる。
〇★三角関数では、角度の大きさを表す単位として度数法のほかに弧度法が使われる。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
3 		数学の基礎 	2 	線形代数 	② 	5.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++　　

ベクトル　(4,7)

　　向きと長さを持った矢印として表現できる
　　数が１つの方向にならんでいる

位置ベクトル
　　原点（0,0）を始点とするベクトル

横ベクトルは空間での位置、縦ベクトルは向きと大きさを持つ位置ベクトル

スカラー
　　単なるひとつの数字

ノルム　norm　標準・基準★★
  ベクトルの大きさをスカラーで表現すること★★
　ユークリッド距離　ベクトルを平面上の原点からの直線距離として図る　L1ノルム　√x²+ｙ²★★
　マンハッタン距離　直線でなく道路に沿って進んだ距離　L2ノルム　ｘ＋ｙ★★

内積(ドット積)
　ベクトルどおしの掛け算　ｘ・ｙ
　計算結果はスカラーになる

行列
　行と列の2方向の広がり
　正方行列　行と列のサイズが同じ行列
　単位行列　対角線が全て１、残り０
　行列の演算　足し算と引き算　行数と列数があっている必要がある
　　　　行列とベクトルの掛け算　1　2　*　5　=　1ｘ5＋2ｘ6　＝17
　　　　　　　　　　　　　　　　3　4　　6　=　3ｘ5＋4ｘ6　＝39

　　　　行列と行列の掛け算　
　　　　　　　　1　2）（5　7）＝（1ｘ5＋2ｘ6　1ｘ7＋2ｘ8）　=　17　23
　　　　　　　　3　4）（6　8）＝（3ｘ5＋4ｘ6　3ｘ7＋4ｘ8）　=　39　53

　　　　　　　　横ベクトル　ｘ縦ベクトル
　　ｍｘｓの行列にｓｘｎの行列をかけると、ｍｘｎの行列になる

9. (3, 4) で表現されるベクトルをAとする。(4, 7)で表現されるベクトルをBとする。(2, 4, 5) で表現されるベクトルをCとする。
次のベクトルに関する記述のうち正しいものはどれか。

〇Aの原点からのユークリッド距離は5である。
ＸBの原点からのマンハッタン距離は9である。
ＸAとBの内積は36である。　3＊4　＋　4＊7
ＸAとCの和は18である。
ＸAとCの差は52である。


Ｘ行と列のサイズが同じ行列を特に正方行列と呼び、正方行列のうち、対角成分がすべて0で、残りの要素が1の行列を単位行列と呼ぶ。
〇ベクトルと同じように要素同士の足し算と引き算で、行列の足し算と引き算を定義することができるが、2つの行列の行数と列数が合っている必要がある。
〇行列の列の数とベクトルのサイズが同じ場合は、これらの掛け算を定義することができ、結果は、元の行列の行数と同じサイズのベクトルになる。
〇行列同士の掛け算は行列となる。数値の掛け算は順番を入れ替えても同じ結果となるが、行列の掛け算は順番を入れ替えると同じ結果になるとは限らない。
〇m×sの行列にs×nの行列を掛けると、m×nの行列になる。これを逆に考えると、データ分析や機械学習において、説明変数の次元数を削減することができる。

〇行と列のサイズが同じ行列を特に正方行列と呼ぶ。正方行列のうち、【対角成分】がすべて1で、残りの要素が0の行列を単位行列と呼ぶ。
〇行列の列の数とベクトルのサイズが同じ場合は、これらの掛け算を定義することができ、結果は、元の行列の行数と同じサイズのベクトルになる。
Ｘ行列同士の掛け算は行列となる。数値の掛け算は順番を入れ替えても同じ結果となるが、行列の掛け算は順番を入れ替えると同じ結果になることはない。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
3 		数学の基礎 	2 	3 	基礎解析 	1 	2.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++　

積分は面積 面積を表現する関数F
微分は傾き

11. 右辺が6x^2（6掛けるxの二乗）で表現される関数をf(x)とする。微分積分に関する以下の記述のうち誤っているものはどれか。
〇関数f(x)を微分すると、右辺は12xとなる。
Ｘ関数f(x)を積分すると、右辺は3x^3となる。
〇積分の範囲が決められていないものを不定積分、範囲が決められているものを定積分という。
〇微分は傾き、積分は面積と捉えることができる。データ分析や機械学習において、関数の傾きが0となる点は有益な情報として利用される。
〇多変数関数の微分を偏微分という。偏微分の場合、変数が複数あるので、どの変数で微分したのかを示すことが必要となる。

〇関数 F(x)を微分して f(x)となったとき、F を f の原始関数、f を F の導関数と呼ぶ。
〇積分の範囲が定められていない積分を不定積分という。任意の定数を微分すると0になるため、不定積分には積分定数「C」が通常含まれる。
〇微分は傾き、積分は面積と捉えることができる。データ分析や機械学習において、関数の傾きが0となる点は有益な情報として利用される。
〇2つ以上の変数を持つ多変数関数の微分を偏微分という。偏微分ではどの変数で微分したのかを示すことが必要である。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
3 		数学の基礎 	2 	4 	確率と統計 	2 	5.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++　

代表値
　　最小値 minimum
    最大値 maximum
    平均値 mean
　　中央値 median
    最頻値 mode
    分位数 四分位数　第２四分位数が中央値になる★★
　　ばらつきの指標
　　　　第３四分位数と第１四分位数の差を四分位範囲（IQR）

分散　ばらつき
　　　　　n
　　　1/n∑(xi−x平均)2
　　　　i=1
度数分布表
　　データの最大値と最小値を等間隔に区切る　階級
　　
ヒストグラム★★
　　度数分布表を棒グラフにしたもの★★
　　縦軸の度数を対数表示（LOG表示）にすると良い★★

箱ひげ図（box　plot）ボックスプロット
　　　　　上下のひげは最大値と最小値
　　　　　四分位範囲（IQR）より1.5倍以上離れているのを外れ値とする★★

散布図
　　２種類以上データがある場合、それらをｘ軸とｙ軸に割り当てる
　　3つある場合、通常は3つのデータから２つを選ぶ組み合せを作る

相関係数
　　共分散　2種類のデータがある場合のばらつき★★分散
　　　　　n
　　　1/n∑(xi−x平均)(ｙi−ｙ平均)
　　　　i=1
　　相関係数は共分散を２つの標準偏差で割ったもの★★
　　　　　必ず-1～1の範囲になる

　　
ピアソンの積率相関係数
スピアマンの順位相関係数

全事象　U={1,2,3,4,5,6}

１～6が出る確率100％　P(U)=1
3が出る（A）の確率　　P(A)=1/6　
偶数が出る（B）の確率　　P(B)=3/6＝1/2

条件付き確率
　　偶数が出て3が出る　1/6　/　1/2　＝1/3

ベイズの定理

確率分布
　　確率変数　X
　　3出る確率　　P(X=3)=1/6　

期待値　E(X)
分散　　V(X)
離散的な場合　確率質量関数★★
連続的な場合　確率密度関数★★
離散一様分布　サイコロの例を一般化した確率分布
正規分布　x=0で最も高い値、左右対称　ガウス分布

12. 確率と統計に関する次の記述のうち、正しいものはどれか。
Ｘ5段階評価のアンケートの回答で、もっとも回答者数が多かった評価が4であった場合、このアンケートの中央値は4であるといえる。
Ｘ分散は、すべてのデータの平均値からの差分をデータの個数で割った値である。
Ｘ12面体のサイコロを1回振った場合の期待値は6である。＜---　6.5である
〇6面体のサイコロを1回振った場合、その出目の数自体は不明なものの、奇数がでていることを教えられたとする。この場合の確率を条件付き確率と呼び、これはベイズの定理の基本となっている。
Ｘ確率変数を引数にとって値を返す関数のうち、確率変数が離散的な場合を確率密度関数、確率変数が連続的な場合を確率質量関数という。標準正規分布などの確率分布は確率質量関数から得ることができる。



13. 「ネイピア数、tan(45°)、1の対数、円周率、1の階乗」の5つの数からなるデータがある。このデータについて正しいものはどれか。 
Ｘネイピア数は円周率より大きい
Ｘtan(45°)は中央値より大きい
〇最頻値は1である
Ｘ算術平均は中央値より小さい
Ｘ中央値は2より大きい

13. 「ネイピア数、sin(30°)、1の対数、円周率、0の階乗」の5つの数からなるデータがある。このデータについて正しいものはどれか。
Ｘ最頻値は1である
Ｘsin(30°)は中央値より大きい
Ｘ算術平均は中央値より小さい
Ｘネイピア数は円周率より大きい
〇0の階乗は1の対数より大きい

13. 「ネイピア数、cos(60°)、1の対数、円周率、4の階乗」の5つの数からなるデータがある。このデータについて正しいものはどれか。
Ｘ最頻値は1である
〇算術平均は中央値より大きい
Ｘ中央値は円周率より大きい
Ｘcos(60°)は中央値より大きい
Ｘ1の対数はcos(60°)より大きい

*1の対数=0
tan(45°)=1
sin(30°)=1/2
cos(60°)=1/2
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
4 		ライブラリによる分析実践 	1 	NumPy 	6 	15.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
df.values　pandasデータフレームdfをNumPy配列に変換する処理
ナンパイ ナンパイ

配列や行列を効率よく行う
配列用の型　ndarray★★
行列用の型　matrix★★

import numpy as np
a = np.array([1, 2, 3])
print(a)  ==> [1, 2, 3]

type(a) ==> numpy.ndarray★★オブジェクトの型を確認

a.shape  ==> (3, )  一次元配列★★

c2 = c1.reshape((2, 3))
c2  ==> array([0, 1, 2],[3, 4, 5])

c3=c2.ravel()  1次元配列に戻す 参照を返す★★浅いコピー
c3  ==> array([0, 1, 2, 3, 4, 5]) 

c4 = c2.flatten() #copy　コピーを返す★★深いコピー

a.dtype 配列要素のデータの型を確認★★データ型を確認
dtype('int64')

★浅いコピー
a= array([ 1, 2, 4]) 
a1=a
a1 => array([ 1, 2, 4]) 

a1[1]=5
a1 =>  array([ 1, 5, 4]) 
a  =>  array([ 1, 5, 4]) 

★深いコピー
a2 = a.copy()
a2
a2 =>  array([ 1, 5, 4]) 
a2[0]=6
a2 =>  array([ 6, 5, 4]) 
a =>  array([ 1, 5, 4]) 

参照の場合、浅いコピー

スライスの場合、
pythonリストは深いコピー★★★★★★
Numpyは浅いコピー（参照）★★★★★★

np.arange(5) => array([ 0, 1, 2, 3, 4]) 

np.arange(1, 5) => array([ 1, 2, 3, 4]) 

np.arange(1, 5, 2) => array([  1,  3]) 

np.random.seed(123)
np.random.random((3, 2)) *0-1の間のランダムな要素3行2列で表示 引数タプル★★★★

np.random.rand(3, 2)  *0-1の間のランダムな要素3行2列で表示　引き数2つ★★★★

np.random.randint(1, 10)　1～9の任意の整数　＝＞3★★★★

np.random.randint(1, 10, (3, 3))　3行3列

np.random.uniform(0.0, 5.0, size=(3, 3))　0.0～5.0の範囲★★★★
np.random.uniform(size=(3, 3)) 0-1の範囲になる

正規分布　-1～1
np.random.randn(3, 2) 平均0　分散1　3行2列で★★★★

np.random.normal(平均, 標準偏差, size=(3, 3)) ★★★★

np.zeros(3) => ([0., 0., 0.])

np.ones(3) => ([1., 1., 1.])★★s

np.arange(0.1, 1.0, 0.1) #

単位行列

np.eye(3) 対角要素を持った単位行列を作る
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])

np.full(3, 3.14) => 指定値　array([3.14, 3.14, 3.14])★★
np.full((2, 4), np.pi)

np.nan => nan 
not a number 数値でない

np.linspace(0, 1, 5) 0から1までを等間隔に区切った5つの要素★★★★
=>array([0.,  0.25 , 0.5, 0.75, 1,])

np.diff() 要素間で差分をとる
p = np.array([2, 2, 6, 1, 3])
np.diff(p)
[0,4,-5,2]

np.concatenate([a, a1])
np.concatenate([a, a1], axis=1) 列を増やす

np.hstack([a, a1])列を増やす★★

np.vstack([a, a1])行を増やす★★

分割
b3
array([[1, 2, 8],
       [4, 5, 8],
       [30, 60, 45]])
1つ目の配列に2列、残り1列が2つ目
first, second = np.hsplit(b3, [2])★★★★★★
first 
array([1, 2],[4, 5], [60, 60])
second
array([8],[8], [45])
・行方向
first, second = np.vsplit(b3, [2])

転置
2次元配列の行列入れ替え
b3
array([[1, 2, 8],
       [4, 5, 8])
b.T★★
array([[1, 4],
       [2, 5],
       [8, 8]])

次元追加★★★★★★★★★★
a=array([1, 2, 8])
行方向にスラッシング
a[np.newaxis,:]★★★★★★
array([[1, 2, 8]])

a[:, np.newaxis]★★★★★★
array([[1],
       [2],
       [8]])

グリッドデータの生成
m=np.arange(0, 4)★★★★
array([0, 1, 2, 3])
n=np.arange(4, 7)
array([4, 5, 6])

xx, yy = np.meshgrid(m, n)★★★★★★
xx  
array([[0, 1, 2, 3],
       [0, 1, 2, 3],
       [0, 1, 2, 3]])
yy
array([[4, 4, 4, 4],
       [5, 5, 5, 5],
       [6, 6, 6, 6]])

mを行方向、nを列方向に、第一引数mの配列の長さ分コピー

ユニバーサルファンクション
np.abs(b)
np.sin(e)
np.cos(e)
np.log(a)
np.exp(a)
ブロードキャスト
　NumPyでは直接演算ができる、加算、減算、積
　c - np.mean(c)
 
ドット積★★★★★★★★
　ベクトルどおしの掛け算　ｘ・ｙ
　計算結果はスカラーになる
　np.dot(b, a) = b @ a
l= np.array([[1,2],[4,5],[7,8]])
a= np.array([[2,3]]).reshape(2,1)
np.dot(l,a)★★★★★★★★★★★★★★★★★★★★★★★★
output
array([[ 2,  6],
       [ 8, 15],
       [14, 24]])

l= np.array([[1,2],[4,5],[7,8]])
a= np.array([[2,3]]
np.multiply(l,a)
output:
array([[ 8],
       [23],
       [38]])

np.count_nonzero(b > 0) 条件に合う要素のカウント　=　np.sum(b > 0)

np.any(b > 0)　どれかあればtrue★★★★
np.all(b > 0)　全てならtrue★★★★

真偽値配列を使って、条件に合致したものだけの要素を新たな配列として出力★★★★
b[b > 0]

配列同士の比較★★★★
b == c
array([[[false, false, false],
       [false, false, false]])

同じ要素で構成されているか★★★★
np.allclose(b, c)
np.allclose(b, c, atol=10) atolで誤差指定★★

〇★NumPyは配列や行列を効率よく扱うためのPythonのサードパーティ製パッケージで、配列用の型であるndarrayと【行列用の型であるmatrix】がある。
〇★NumPyオブジェクトの型を確認するためには【type関数を、NumPy配列の形状を確認するためにはshapeメソッド】を用いることができる。
〇★NumPy配列の次元の変換を行うためにはreshapeメソッドを、2次元のNumPy配列を1次元に変換するには【ravelメソッド】または【flattenメソッド】を用いることができる。
Ｘ★NumPy配列の次元変換に用いるravelメソッドは深い参照を返し、flattenメソッドは浅いコピーを返す。
〇★NumPy配列の要素のデータ型を確認するには、dtype属性を用いることができる。

＊ravelメソッドは参照を返します。一方、flattenメソッドはコピーを返します。
また参照を「浅いコピー」、そうでない場合を「深いコピー」ともいいます。

〇NumPyオブジェクトの型を確認するためにはtype関数を、NumPy配列の要素のデータ型を確認するにはdtype属性を用いることができる。
〇NumPy配列の形状を変形するためにはreshapeメソッドを、NumPy配列の要素のデータ型を変換するためには【astypeメソッド】を用いることができる。
〇★★Numpy配列ではPython標準のリストと同様、要素を取り出すためにインデックスとスライスを使うことができる。
ＸNumPyは配列や行列を効率よく扱うためのPythonのサードパーティ製パッケージで、行列用の型であるndarrayと配列用の型であるmatrixがある。

np.eye(5)　単位行列生成
10000
01000
00100
00010
00001

★a = np.full((1, 5), np.e).T.ravel()
full関数にタプルで1×5行列の指定と、np.e（Numpyの定数でネイピア数を表すもの）の指定をすることで、ネイピア数だけからなる1×5の2次元配列ができます。
これに対してT属性で転置がなされ、5×1の2次元配列になります。
さらにこれに対しravelメソッドが使われ1×5の1次元配列になります。

np.linspace(0, 1, 5) 0から1までを等間隔に区切った5つの要素
=>array([0.,  0.25 , 0.5, 0.75, 1,])

np.hstack([a, a1])列を増やす
log2+log5 = log10

b = np.log10(a)
log10関数で、底を10とするaの対数の計算


a = np.array([1, 3])
b = np.array([-1, 5])
d = a @ b   ドット積 [1, 3]*[-1, 5]=1*-1 + 3*15=14★★★★★★

e = np.dot(c, a) [[1 2][3 4]] * [1 3]=[1 2]*[1 3] + [3 4]*[1 3] =[7, 15]★★

np.pi　3.141
np.e　　2.718

(1)(01)　-＞　　(01)
 0               00
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
4 		ライブラリによる分析実践 	2 	pandas 	7 	17.50%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Series 1次元のデータ★★★★
ser = pd.Series([10, 20, 30, 40])

ser

0 10
1 20
2 30
3 40

DataFrame は2次元のデータ★★
df = pd.DataFrame([[10, "a", True],[20, "b", False],[30, "c", False],[40, "a", False]])

df.head()  最初の5行のみ出力
df.tail()  最後の5行のみ出力

DataFrame のサイズを知る
df.shape　　=> (25, 4)

df.loc[:, "A"]  Aカラムを全てSeriesとして抽出

1行目 20
2行目 30
3行目 40

df.loc[:, ["A","B"]] = df.loc[["A","B"]]★★★★locはインデックス名とカラム名
　　　A　　B
1行目 20　　1
2行目 30　　4
3行目 40　　7

インデックス方向の抽出

df.loc["1行目", : ] 
A 20
B 1
C 5

df.loc[["1行目","3行目"], : ] 
　　　A　　B     C
1行目 20　　1    2
3行目 40　　7    8

df.loc[["1行目"], ["A","B"]]

iloc[インデックス番号, カラム番号]★★ilocはインデックス番号, カラム番号
df.iloc[1, 1] =>　5

df.iloc[1:, 1] 
2行目 30　　4
3行目 40　　7
4行目 30　　4
5行目 40　　7

pd.read_csv pd.to_csv

pd.read_excel pd.to_excel

pd.read_html

pd.to_pickle DataFrame形式で書き込み　読み込みpd.read_pickle★★

データを整形
df = pd.read_excel["xx.xlsx"]

df["歩数"] >= 100000

df_selected = df[df["歩数"] >= 100000]　歩数が10000以上のレコードを抽出

df.query('歩数 >= 100000 and 接種カロリー <= 1000')★★

1か月分のデータを作る

dates=pd.date_range(start="2017-04-01",end="2017-04-30")★★

1年分

dates=pd.date_range(start="2017-01-01",periods=365)★★

1年分の土曜日

dates=pd.date_range(start="2017-01-01",end="2017-12-31", freq="W-SAT")★★

df = pd.DataFrame(np.random.randint(1, 31, 365), index=dates, clumns=["乱数"])

月平均のデータにする

df.groupby(pd.Goruper(freq='M')).mean()★★★★

欠損値削除 NaN

df_201705.dropna()

df_201705.fillna(0) 欠損値は0

df_201705.fillna(method='ffill') 欠損値にひとつ前の値で補完★★

df_201705.fillna(df_201705.mean()) 欠損値に平均値で補完

列方向に連結 axis=1

pd.concat([df1,df2], axis=1)

axis=0 行方向に連結

■基本統計量
df.loc[:, "摂取カロリー"].max()
df.loc[:, "摂取カロリー"].min()
df.loc[:, "摂取カロリー"].mode() 最頻値
df.loc[:, "摂取カロリー"].mean() 平均
df.loc[:, "摂取カロリー"].median()　中央値
df.loc[:, "摂取カロリー"].std() 標本の標準偏差
df.loc[:, "摂取カロリー"].std(ddof=0)母集団の標準偏差


df.loc[:, "摂取カロリー"]==2300.count() 2300の数★★
df.describe()  まとめで全て表示

相関係数★★
df.corr()

散布図行列

〇WebサイトのHTML内のtable要素からのデータの読み込みは、read_htmlメソッドを、htmlファイルへのデータの書き込みはto_htmlメソッドを用いることができる。
Ｘバイナリファイルからのデータの読み込みは、read_blobメソッドを、バイナリファイルへのデータの書き込みはto_blobメソッドを用いることができる。
〇DataFrameを直列化してファイルとして保存し、再利用するためにpickleモジュールを利用することができる。

〇pandasのデータの読み込みと書き込みの関数はほかにも to_sql やto_jsonなどさまざまなものがある。ただしpandasのバージョンによっても異なる。

＊pickleモジュールはデータを再利用するために、凍結・変換（直列化）と保存（永続化）を行うものです。
　Pythonプログラムで生成したデータを直列化して保存したり、読み込んで再利用したりということが行われています。

＊バイナリ　read_pickle to_pickle★★

np.random.randint(1, 31, 365) 生成する整数の範囲の最小値は1、最大値は「31の一つ手前」、つまり「30」まで

〇欠損値が存在する行や列を削除するメソッドは、dropnaである。
〇fillnaメソッドの引数にmethod='ffill'を与えると、欠損値を1つ前方の値で補完する。
Ｘfillnaメソッドの引数にmethod='median'を与えると、欠損値を中央値で補完する。     --->method=df.median()★★
〇fillnaメソッドの引数にmethod='bfill'を与えると、欠損値を1つ後方の値で補完する。
〇fillnaメソッドの引数に0を与えると、欠損値を0で補完する。

25. DataFrameの基本統計量に関する次の記述のうち、誤っているものはどれか 。
Ｘstdメソッドは分散を取得できる。
〇countメソッドは件数を取得できる。
〇modeメソッドは最頻値を取得できる。
〇medianメソッドは中央値を取得できる。
〇describeメソッドは平均値を取得できる。

Ｘ相関係数は、カラム間のデータの関係を数値で表すものであり、describeメソッドで取得する。
〇★DataFrameをNumPy配列に変換するには、values属性を利用する。この場合、インデックス名、カラム名は保持されない。
Ｘconcat関数は、2つのDataFrameを連結する。引数にaxis=0を加えると列方向の連結となり、axis=1を加えると行方向の連結となる。この場合、行列の順序は必ず保持される。
ＸpandasはNumPyを基盤に2次元のDataFrameと、より多次元のSeriesをデータ型として提供している。
Ｘcorr関数に引数としてDataFrameを渡すと基本統計量グラフを出力することができる。

〇相関係数はcorr関数で出力でき、その値は必ず-1から1の間となる。1に近いほど強い正の相関関係があり、-1に近いほど強い負の相関関係があり、0では相関関係がないといえる。
ＸDataFrameをNumPy配列に変換するには、values属性を利用する。この場合、カラム名は保持されないがインデックス名は保持される。


相関係数の取得に用いるのは、corrメソッドです。

2つのDataFrameをconcat関数で連結するときに、axisが0なら行方向、1なら列方向で連結されます。

df[“利用回数”].value_counts().to_frame()
値ごとの出現回数を数えるvalue_counts関数
Series.to_frame() メソッドで Series をデータフレームに変換する 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
4 		ライブラリによる分析実践 	3 	Matplotlib 	6 	15.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

2次元のグラフを描画するためのライブラリー

mport matplotlib.pyplot as plt

★[MATLABスタイル]

plt.plot(x, y) #折れ線グラフ
plt.title('xxxxxx')
plt.show()

★[オブジェクト指向スタイル]

#描画オブジェクトfigとサブプロットaxを生成■■■■■
fig, ax = plt.subplots()　■■■■■
ax.plot(x, y)
ax.set_title('xxxxxx')
plt.show()

★描画オブジェク
fig, ax = plt.subplots(1,2)  #1行2列のサブプロットを配置
fig, ax = plt.subplots(ncols=2)  #1行2列のサブプロットを配置★★
fig, ax = plt.subplots(nrows=2)  #2行1列のサブプロットを配置★★

★スタイル

# スタイルの一覧を表示
import matplotlib.style
print(matplotlib.style.available)

# グラフのスタイルにclassicを指定
matplotlib.style.use('classic')

★軸ラベル
ax.set_xlabel('x label')
ax.set_ylabel('y label')

★凡例
# 凡例用のラベルを設定
ax.plot([1, 2, 3], [2, 4, 9], label='legend label')
ax.legend(loc='best')  # 凡例を表示
ax.legend(loc='best')データとの重なり位置最小
ax.legend(loc='lower right')  右下に表示

★ファイル出力
fig,saving('xx.png')
fig,saving('xx.svg')  

★折れ線グラフ
plt.plot(x, y) #折れ線グラフ
x = [1, 2, 3]
y1 = [1, 2, 3]
y2 = [3, 1, 2]
ax.plot(x, y1)  # 折れ線グラフを描画
ax.plot(x, y2)



★棒グラフ
x = [1, 2, 3]
y = [10, 2, 3]
labels = ['spam','ham','egg']
ax.bar(x, y, tick_label=labels) #棒グラフを描画
plt.show()

ax.barh(x, y, tick_label=labels)  # 横向きの棒グラフを描画★★

★散布図
ax.scatter(x, y) #散布図を描画★★
plt.show()

★ヒストグラム
mu = 100  # 平均値
sigma = 15  # 標準偏差
x = np.random.normal(mu, sigma, 1000)

fig, ax = plt.subplots()

# ヒストグラムを描画
n, bins, patches = ax.hist(x)

plt.show()

ax.hist(x, bins=25)  # ビンの数を指定して描画★★

ax.hist(x, orientation='horizontal')# 横向きのヒストグラムを描画

# 異なる標準偏差でデータを生成
mu = 100  # 平均値
x0 = np.random.normal(mu, 20, 1000)
x1 = np.random.normal(mu, 15, 1000)
x2 = np.random.normal(mu, 10, 1000)

fig, ax = plt.subplots()

labels = ['x0', 'x1', 'x2']
# 3つのデータのヒストグラムを描画
ax.hist((x0, x1, x2), label=labels)★★
ax.legend()

plt.show()

★箱ひげ図
# 異なる標準偏差でデータを生成

x0 = np.random.normal(0, 10, 500)
x1 = np.random.normal(0, 15, 500)
x2 = np.random.normal(0, 20, 500)

fig, ax = plt.subplots()
labels = ['x0', 'x1', 'x2']
ax.boxplot((x0, x1, x2), labels=labels)  # 箱ひげ図を描画★★boxplot

plt.show()

ax.boxplot((x0, x1, x2), labels=labels, vert=False)# 横向きの箱ひげ図を描画★★


★円グラフ
*デフォルトでは右（時計3時）から反時計周りに順番に配置★★

labels = ['spam', 'ham', 'egg']
x = [10, 3, 1]

fig, ax = plt.subplots()

ax.pie(x, labels=labels)  # 円グラフを描画(楕円)★★pie

plt.show()


ax.pie(x, labels=labels)
ax.axis('equal')  # アスペクト比を保持して描画する#正円描画★★★★★★

ax.pie(x, labels=labels, startangle=90,
       counterclock=False)  # 上から時計回り★★counterclock=False　　　startangle=90　上から
ax.axis('equal')

ax.pie(x, labels=labels, startangle=90,
       counterclock=False,
       shadow=True, autopct='%1.2f%%')  # 影と%表記を追加★★
ax.axis('equal')

ax.pie(x, labels=labels, startangle=90,
       counterclock=False,
       shadow=True, autopct='%1.2f%%',
       explode=explode)  # explodeを指定する 一部の要素を取り出す
ax.axis('equal')


★複数のグラフを組み合わせる

ax.bar(x1, y1, label='y1')  # 棒グラフを描画
ax.plot(x2, y2, label='y2')  # 折れ線グラフを描画
ax.legend()


# ヒストグラムを描画
counts, edges, patches = ax.hist(x, bins=25)

# 近似曲線に用いる点を求める(ヒストグラムのビンの中点)
x_fit = (edges[:-1] + edges[1:]) / 2
# 近似曲線をプロット
y = 1000 * np.diff(edges) * np.exp(-x_fit**2 / 2) / np.sqrt(2 * np.pi)
ax.plot(x_fit, y)

★色の設定
# 線の色を名前で指定
ax.plot([1, 3], [3, 1], label='aqua', color='aqua')
# 16進数のRGBで指定
ax.plot([1, 3], [1, 3], label='#0000FF', color='#0000FF')
# RGBAをfloatで指定
ax.plot([1, 3], [2, 2], label='(0.1, 0.2, 0.5, 0.3)',
        color=(0.1, 0.2, 0.5, 0.3))

# 5.5ポイント★★の幅の線で描画
ax.plot([1, 3], [3, 1], linewidth=5.5, label='5.5')
# 10ポイントの幅の線で描画
ax.plot([1, 3], [1, 3], linewidth=10, label='10')

# 破線で描画
ax.plot([1, 3], [3, 1], linestyle='--', label='dashed')★★
# 一点鎖線で描画
ax.plot([1, 3], [1, 3], linestyle='-', label='dashdot')
# 点線で描画
ax.plot([1, 3], [2, 2], linestyle=':', label='dotted')★★

★フォント
ax.set_xlabel('xlabel', family='fantasy', size=20,
              weight='bold')
ax.set_ylabel('ylabel', family='cursive', size=40,
              weight='light')
ax.set_title('graph title', family='monospace',
             size=25, weight='heavy')

# フォントのスタイルを辞書で定義
fontdict = {
    'family': 'fantasy',
    'size': 20,
    'weight': 'normal',
}
# 辞書形式でフォントのスタイルを指定
ax.set_xlabel('xlabel', fontdict=fontdict)
ax.set_ylabel('ylabel', fontdict=fontdict)
# 個別指定したsizeで上書き可能
ax.set_title('graph title', fontdict=fontdict, size=40)

★テキスト描画
ax.text(0.2, 0.4, 'Text', size=20)  # Textというテキストを描画★★

★pandasのオブジェクトからグラフ描画
matplotlib.style.use('ggplot')  # スタイルを指定

# DataFrameを作成
df = pd.DataFrame({'A': [1, 2, 3], 'B': [3, 1, 2]})
df.plot()  # 折れ線グラフを描画
df2.plot.bar()  # 棒グラフを描画

〇matplotlib.style を利用すると線の色、太さ、背景色などグラフの表示スタイルを指定することができる。
〇★★描画オブジェクトとサブプロットにはそれぞれsuptitleメソッド、set_titleメソッドでタイトルを指定することができる。
〇サブプロットにはlegendメソッドで凡例を表示することができる。legendメソッドの引数に loc="best" を指定するとデータとの重なりが最小な位置に出力できる。
〇作成したグラフをsavefigメソッドでファイルに出力することができる。ファイル形式としては、png、pdf、svgなどが選択可能である。
Ｘ折れ線グラフはplotメソッドで、棒グラフはbarメソッドで、散布図は、histメソッドで、円グラフはcircleメソッドで描画することができる。

Ｘ★★「MATLABスタイル」は描画オブジェクトに対してサブプロットを追加して、サブプロットに対しグラフを描画するため、スクリプトが冗長になる。
〇★★「オブジェクト指向スタイル」は一つのfigureオブジェクトに対して複数のサブプロットを指定できる。つまり複数のグラフをまとめて表示できるという利点がある。
Ｘサブプロットにはlegendメソッドで凡例を表示することができる。legendメソッドの引数に loc="min" を指定するとデータとの重なりが最小な位置に出力できる。
Ｘ★★描画オブジェクトにはset_titleメソッド、サブプロットにはsuptitleメソッドで、それぞれタイトルを指定できる。


fig.suptitle()
ax.set_title()
loc=best
savefigメソッドで任意のファイル名を指定して保存
★★散布図はhistメソッドではなくscatterメソッド、円グラフはcircleメソッドではなくpieメソッドが正しい

〇折れ線グラフの線の幅は指定することができる。たとえば、10ポイントの幅の指定は、plotメソッドの引数に 【linewidth=10】 と指定する。
〇タイトルなどのテキストに対してもスタイルを指定することができる。たとえば、サブプロットのタイトルのフォントファミリーをmonospaceに指定するには、set_titleメソッドの引数に family='monospace' と指定する。
Ｘ★★同じフォントの指定を複数回繰り返す場合、フォントの設定をタプルデータとして作成し、fontdict引数に一度に指定することができる。タプルデータは上書きができないため、誤って上書きされることを防ぎやすい。
〇グラフに表示する線、背景色、枠線などの要素に色を指定することができる。たとえば、赤い折れ線グラフを描画するには、plotメソッドの引数に color='red' と指定する。
〇textメソッドを使用するとグラフに任意のテキストを描画できる。第一、第二引数には描画するテキストの左下のX, Y座標を指定する。また、フォントのスタイルと同様の引数の指定もできる。

〇グラフに表示する線、背景色、枠線などの要素には色を指定できる。色の指定方法には、文字列での色指定、16進数でのRGB指定などがある。
〇折れ線グラフやグラフの枠線、区切り線など、さまざまな線にスタイルを適用できる。linewidth引数を指定すると線の幅を変更でき、その際の単位は【ポイント】である。
〇★★Matplotlibで描画するグラフに日本語を表示するには、日本語フォントの設定が必要である。

x = np.arange(0.0, 15.0, 0.1)　0から0.1ごとに15の1つ手前まで、つまり14.9までの配列を生成

zip関数　 複数のリストの要素をまとめて取得
　　y_total = [num1 + num2 for num1, num2 in zip(y1, y2)] 

numpyのrandom.normal関数で正規分布に従う乱数を生成
np.random.normal(mu,sigma,1000)
mu  平均値
sigma 標準偏差
つ目が出力件数

ax.pie(x, labels=labels, startangle=90, counterclock=False, shadow=True, autopct=’%1.2f%%’)
 startangle引数に、（デフォルトとは異なる）90°を設定して、円グラフの12時の位置を、開始位置に指定します。
 counterclock引数を確認します。これにはFalse（時計回り）の指定
 autpct引数に、値をパーセント表示させるための指定がされています。 
 具体的には右のように、まず書式化演算子%で、最低限表示させたい桁数（ここでは1桁）が指定されています。
 ドットの後に、数字とfの組み合わせで精度（つまり小数点以下は今回2桁まで）が指定されています。
 そして最後に％演算子ともう一つの%を指定し一個の%を表示させています。

〇np.sin(x)、np.cos(x)は、それぞれ引数「x」を弧度法のラジアンで処理する。
＊histメソッドのデフォルトのビン数は10

ｘ描画オブジェクトにはset_titleメソッド、サブプロットにはsuptitleメソッドで、それぞれタイトルを指定できる。【逆】
〇棒グラフとは異なり、ヒストグラムでは複数の値を指定すると、自動的に横に並んだ状態で表示される。★★★★

ｘ棒グラフや散布図には、color引数またはedgecolor引数のどちらか一方が指定できる。color引数には塗りつぶしの色を、edgecolor引数には枠線の色を指定する。
〇散布図では、デフォルトではそれぞれのマーカーは丸で描画されるが、marker引数にマーカーの形を指定することにより、様々な形のマーカーを使用することができる。
ｘ同じフォントの指定を複数回繰り返す場合、フォントの設定をタプルデータとして作成し、fontdict引数に一度に指定できる。タプルはイミュータブルなため、誤って上書きされることを防ぎやすい。

＊edgecolor 	図の枠の色
　facecolor 	図の背景色。
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
4 		ライブラリによる分析実践 	4 	scikit-learn 	8 	20.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
〇カテゴリ変数のエンコーディングとは、文字のaを数値の0、bを1、cを2のようにカテゴリ変数を数値に変換する処理をいう。
GPUで動かすためのサポートがない

機械学習を含むデータマイニングやデータ解析のライブラリ

■前処理
　　・欠損値への対応
　　・カテゴリ変数のエンコーディング
　　・特徴量の正規化

■欠損値への対応

　1.欠損値を除去
　2.欠損値を補完

欠損値かどうか
df.isnull()

欠損値の除去
df.dropna()

欠損値の補完
  特徴量の平均値、中央値、最頻値などで補完

from sklearn.preprocessing import Imputer
# 平均値で欠損値を補完するインスタンスを作成する
imp = Imputer(strategy='mean', axis=0)　　# axis=0　列方向　1　行方向★★★★
# 欠損値を補完
imp.fit(df)★★
imp.transform(df)

■カテゴリ変数のエンコーディング
df=pd.DataFrame({'B':['a','b','c','a','a','c']})
from sklearn.preprocessing import LabelEncoder  ★★
# ラベルエンコダーのインスタンスを生成
le = LabelEncoder()  ★
# ラベルのエンコーディング
le.fit(df['B'])  ★★
le.transform(df['B'])  ★

array([0, 1, 0, 1, 2])

# 元の値を確認
le.classes_★★★★

array(['a','b','c','a','a','c'], dtype=object)

■One-hotエンコーディング★★
〇One-hotエンコーディングでは、たとえば、テーブル形式のデータのカテゴリ変数の列について、取り得る値の分だけ列を増やして、
　各行の該当する値の列のみに1を、それ以外の列には0を入力するように変換する処理をいう。

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
# DataFrameをコピー
df_ohe = df.copy()
# ラベルエンコーダのインスタンス化
le = LabelEncoder()
# 英語のa、b、cを1、2、3に変換
df_ohe['B'] = le.fit_transform(df_ohe['B'])
# One-hotエンコーダのインスタンス化　
ohe = OneHotEncoder(categorical_features=[1])##変換する列名を指定 categorical_features=[1]
# One-hotエンコーディング
ohe.fit_transform(df_ohe).toarray()

■特徴量の正規化
特徴量の大きさをそろえる処理
分散正規化　特徴量の平均が0，標準偏差を1となるように変換★★
〇特徴量の正規化とは、たとえば、ある特徴量の値が2桁の数値（数十のオーダ）、別の特徴量の値が4桁の数値（数千のオーダ）のような場合、
　後者のオーダの特徴量が重視されやすくなるため、尺度を揃える処理をいう。
Ｘ分散正規化とは、特徴量の平均が1、標準偏差が0となるように特徴量を変換する処理であり、標準化やz変換と呼ばれることもある。

from sklearn.preprocessing import StandardScaler ★★
# 分散正規化のインスタンスを生成
stdsc = StandardScaler()
# 分散正規化を実行
stdsc.fit(df)
stdsc.transform(df)

array([[-1.41421356, -1.22474487],
       [-0.70710678, -0.81649658],
       [ 0.        ,  0.        ],
       [ 0.70710678,  0.40824829],
       [ 1.41421356,  1.63299316]])

最小最大正規化
　特徴量の最小値が0，最大値が1をとるように特徴量を正規化する★
　〇★★最小最大正規化とは、特徴量の最小値が0、最大値が1を取るように特徴量を正規化する処理であり、scikit-learnでは、preprocessingモジュールの
　　【MinMaxScalerクラス】を用いて実行することができる。

from sklearn.preprocessing import MinMaxScaler ★★
# 最小最大正規化のインスタンスを生成
mmsc = MinMaxScaler()
# 最小最大正規化を実行
mmsc.fit(df)
mmsc.transform(df)

array([[0.        , 0.        ],
       [0.25      , 0.14285714],
       [0.5       , 0.42857143],
       [0.75      , 0.57142857],
       [1.        , 1.        ]])

■分類
まず手元のデータセットを学習用とテスト用に分割します。

from sklearn.datasets import load_iris
# Irisデータセットを読み込む
iris = load_iris()
X, y = iris.data, iris.target

from sklearn.model_selection import train_test_split★★
# 学習データとテストデータに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)★★

■サポートベクタマシン



■決定木


■ランダムフォレスト


■回帰




■ モデルの評価

指標
・適合率（precision）　tp/(tp+fp)　正例予測したデータのうち、実際の正例の割合★★★★
・再現率（recall）     tp/(tp+fn) 実際の正例のうち、正例と予測したもの★★★★
・F値（F-value）　　適合率と再現率の調和平均　2/（1/適合率　＋　1/再現率）＝2＊適合率＊再現率/（適合率＋再現率）★★★★★★★★
・正解率（accuracy）予測と実績が一致したもの　(tp+tn)/(全体)

[混合行列]　予測と実績のクラスレベルの組合せを集計した表

tp;正例として予測して、実際に正例　true positive　〇

fp:正例として予測して、実際に負例　false positive　　ｘ

fn;負例として予測して、正例　true nagativeｘ

tn;負例として予測して、負例　false nagative

from sklearn.metrics import classification_report　〇
# 適合率、再現率、F値を出力
print(classification_report(y_test, y_pred))★★★★

＊混同行列で計算する適合率、再現率、F値、正解率は、（回帰ではなく）分類モデルの評価指標★★★★
＊適合率は予想するクラスをなるべく間違えないようにしたいときに重視する指標である。★★★★★★★★★★★★
＊正解率は、正例か負例かを問わず、予測と実績が一致したデータの割合を表す。正解率は(tp+tn)/(tp+fp+fn+tn）で計算することができる。★★★★★★★★★★★★
＊F値は、適合率と再現率の【調和平均【として定義される。F値は2*適合率*再現率/(適合率+再現率)で計算することができる。★★★★
Ｘ★★機械学習を用いて構築した【回帰モデルの良し悪し】を評価する指標に適合率、再現率、F値、正解率がある。これらは【混同行列】から計算する。
〇適合率、再現率、F値、正解率は、機械学習を用いて構築した【分類モデルの良し悪し】を評価する指標であり、混同行列から計算する。

〇一般的に適合率と再現率はトレードオフの関係にある。つまり、どちらか一方の指標を高くすると、もう一方の指標は低くなる。

ｘ適合率は、たとえば病院の検診で病気の見逃し・取りこぼしがないようにしたい場合などに重視される、網羅性に関する指標である。
ｘ再現率は、間違えることをできるだけ避けたい場合に重視する指標である。一般的に適合率と再現率はトレードオフの関係にある。
■交差検証（クロスバリデーション）★★★★★★★★★★★★

データセットを学主用とテスト用に分割する処理を繰り返し、モデルの構築と評価を繰り返し、
モデルの構築と評価を複数回数行う処理
〇★★学習とモデルの評価は、学習データセットとテストデータセットの分割を繰り返し、モデルの構築と評価を複数回行う方法で行うこともできる。この方法を交差検証という。
ｋ分割交差検証　9割学習用データ、1割テストデータにする処理を10回行う＝10分割交差検証

層化ｋ分割交差検証　目的変数のクラスの割合が一定

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
# サポートベクタマシンをインスタンス化
svc = SVC()
# 10分割の交差検証を実行
cross_val_score(svc, X, y, cv=10, scoring='precision')　　適合率（precision）　★★

＊引数cvに、10分割の交差検証を指定

■予測確立の正確さの定量化
予測退会確率の高い順に並べる
為陽性率　負例全件中の負例何件を割合表示
真陽性率　正例全件中の正例何件を割合表示
指標
　ROC曲線　横　為陽性率　縦　真陽性率★★★★★★★★★★★★
　AUC　0.5に近づくほど、正例と負例を区別できない★★★★★★★★★★★★
　　　1に近づくほど、確率が相対的に高いサンプルが正例、低いサンプルが負例になる傾向
　　　
■ハイパーパラメータの最適化

ハイパーパラメータ　人が決める　決定木の個数

★グリッドサーチ
　指定したパラメーターの全ての組み合わせを試す手法。組み合わせの総数分モデルの学習を行うので、探索が終わるのに時間がかかる
ランダムサーチ

■次元削減


■主成分分析


■クラスタリング



■k-means


■階層的クラスタリング





■汎化能力
〇構築したモデルのテストデータセットに対する予測を行い、未知のデータに対する対応能力
Ｘ構築したモデルが持つ未知のデータに対する対応能力を「汎化能力」という。


〇★★分類モデルを構築するには、まず手元のデータセットを学習データセットとテストデータセットに分割する。そして、学習データセットを用いて分類モデルを構築し、
　構築したモデルのテストデータセットに対する予測を評価し、汎化能力を評価する。

〇学習データセットとテストデータセットの分割は、scikit-learnでは、model_selectionモジュールの【train_test_split関数】を用いて実行することができる。


Ｘscikit-learnのインターフェースでは、学習はfitメソッド、予測はestimateメソッドを用いて実行できる。


X, y = boston.data, boston.target 
〇boston.dataには説明変数、boston.targetには目的変数が格納されている。

ポアソン分布　交通事故の発生回数の予測、機械部品の故障予測など、稀に生じる事象についてモデル化したい場合に用いられる、離散型の確率分布である。
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
5		スクレイピング 	0 	0.00%
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

s = ‘　DIVE INTO CODE　’ 
s.strip() 両端空白、\t削除
'DIVE INTO CODE”

〇Jupyter Notebookがデータ分析や機械学習の分野でよく使われる理由として、1つのNotebookというドキュメントにPythonなどのプログラムとその結果やMarkdown記法のドキュメントなどをまとめられることのほか、
　コードの実行結果の表示は、通常の文字列に加え、表やグラフも可能であることなどが挙げられる。

〇cosh（ハイパボリックコサイン）のグラフの形は、「懸垂線」「カテナリー曲線」と呼ばれ、ロープの両端を持った時に見られる曲線の形を表現している。
〇シグモイド関数のグラフの形は、座標点（0, 0.5）を基点として点対象の、S字型曲線である。
〇ネイピア数とは数学定数の一つで、自然対数の底であり、通常「e」の記号で表現される。対数関数で底が省略された場合には、「e」なのか「10」なのかは注意が必要である。
〇三角関数では、角度の大きさを表す単位として度数法のほかに弧度法が使われる。

〇行列の分解の理論「m×sの行列にs×nの行列を賭けると、m×nの行列になる」を逆に考えると、データ分析や機械学習において、説明変数の次元数を削減することができる。
ｘ行列の行の数とベクトルのサイズが同じ場合は、これらの掛け算を定義することができ、結果は、元の行列の列数と同じサイズのベクトルになる。

ｘ中央値とは、データを小さい順に並べてちょうど真ん中に来る値である。データの個数が偶数の場合には、ちょうど真ん中にくるデータがないため、中央値は存在しないことになる。
〇確率変数を引数にとって値を返す関数のうち、確率変数が離散的な場合を確率質量関数、確率変数が連続的な場合を確率密度関数という。
  標準正規分布などの確率分布は確率密度関数から得ることができる。

ｘNumpyではPython標準のリストと同様、要素を取り出すためにスライスを使うことができる。Python標準のリストではスライスした結果は参照が返され、
  Numpyではスライスの結果はコピーが返される。

import numpy as np
a = np.array([7,8,9])
b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a.shape, b[0:1, [1,2]])

正答: (3,) [[2 3]]

〇read_htmlメソッドを使うと、WebサイトのHTML内のtable要素をDataFrameに取り込むことができる。read_htmlの結果はDataFrameのリストになっており、table要素が複数ある場合もインデックス番号を指定することで目的のテーブルを取得できる。
ｘ抽出条件をつけずDataFrameのすべてを、たとえば「df.loc[:, :]」として出力した場合には、参照ではなくコピーが返される。

ｘ行数の多いDataFrameを確認するときにheadメソッドとtailメソッドが役に立つ。特に引数を指定しない場合、headメソッドは先頭10行【5行】を、tailメソッドは末尾10行を返す。





。

